<!DOCTYPE html>
<html lang="ko"><head>
  <meta charset="utf-8" />
  <meta name="author" content="DAEHEE KIM" />
  <meta name="description" content="Personal blog." />
  <meta name="keywords" content="blog, tech" />
  <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">

  <link rel="canonical" href="http://clonekim.github.io/posts/2018/2018-12-24-aggregation-tags-with-spark/">
  <base href="http://clonekim.github.io/" />
  <meta property="og:title" content="Spark" />
<meta property="og:description" content="현재 특정 테이블의 태그정보와 아래와 같다
특정컬럼에 태그 값이 컴마 구분으로 들어있음
   tags     태그, 태그, 태그 &hellip;    파일 처리 해당 컬럼만 csv로 만들어본것
# -*- coding: utf-8 -*- from pyspark import SparkConf from pyspark import SparkContext from pyspark.sql import SparkSession from pyspark.sql.types import * lines = sc.textFile(&#39;[csv파일]&#39;, use_unicode=True) counts = lines.flatMap(lambda line: line.split(&#39;,&#39;)).map(lambda word: (word,1)).reduceByKey(lambda a,b : a &#43; b) schema = StructType([ StructField(&#39;tag&#39;, StringType(), False), StructField(&#39;count&#39;, IntegerType(), False), ]) df = spark." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://clonekim.github.io/posts/2018/2018-12-24-aggregation-tags-with-spark/" />
<meta property="article:published_time" content="2018-12-24T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2018-12-24T00:00:00&#43;00:00"/>

  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Spark"/>
<meta name="twitter:description" content="현재 특정 테이블의 태그정보와 아래와 같다
특정컬럼에 태그 값이 컴마 구분으로 들어있음
   tags     태그, 태그, 태그 &hellip;    파일 처리 해당 컬럼만 csv로 만들어본것
# -*- coding: utf-8 -*- from pyspark import SparkConf from pyspark import SparkContext from pyspark.sql import SparkSession from pyspark.sql.types import * lines = sc.textFile(&#39;[csv파일]&#39;, use_unicode=True) counts = lines.flatMap(lambda line: line.split(&#39;,&#39;)).map(lambda word: (word,1)).reduceByKey(lambda a,b : a &#43; b) schema = StructType([ StructField(&#39;tag&#39;, StringType(), False), StructField(&#39;count&#39;, IntegerType(), False), ]) df = spark."/>

  
  
<meta itemprop="name" content="Spark">
<meta itemprop="description" content="현재 특정 테이블의 태그정보와 아래와 같다
특정컬럼에 태그 값이 컴마 구분으로 들어있음
   tags     태그, 태그, 태그 &hellip;    파일 처리 해당 컬럼만 csv로 만들어본것
# -*- coding: utf-8 -*- from pyspark import SparkConf from pyspark import SparkContext from pyspark.sql import SparkSession from pyspark.sql.types import * lines = sc.textFile(&#39;[csv파일]&#39;, use_unicode=True) counts = lines.flatMap(lambda line: line.split(&#39;,&#39;)).map(lambda word: (word,1)).reduceByKey(lambda a,b : a &#43; b) schema = StructType([ StructField(&#39;tag&#39;, StringType(), False), StructField(&#39;count&#39;, IntegerType(), False), ]) df = spark.">


<meta itemprop="datePublished" content="2018-12-24T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2018-12-24T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="250">



<meta itemprop="keywords" content="spark," />

  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
  <title>Bonjour!</title>
  <style>
   pre {
     margin: 1em 0em 1em;
     padding: 0.5em 0.5em 0.5em;
     border: 1px solid #5C5C5C;
   }

   code {
     white-space: pre-wrap;        
     white-space: -moz-pre-wrap;   
     white-space: -pre-wrap;       
     white-space: -o-pre-wrap;     
     word-wrap: break-word;        
     line-height: 1.4em;
   }

   blockquote { background: #1D1F21; border-left: 3px solid #99cc66; }
   table { margin: 1em auto; border-collapse: collapse; }
   table, th, td { border: 1px solid #5C5C5C; }
   tr:hover { background: #1D1F21; }
  </style>
  <link rel="stylesheet" href="css/tomorrow-night.min.css" />
  <script src="js/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>
<body><h3><a href="http://clonekim.github.io/">Bonjour!</a></h3>
<div id="content" class="container">
<div class="card border-primary">
  <div class="card-header text-right">
    <small>Dec 24, 2018</small>
  </div>
  <div class="card-body">
    <a  href="http://clonekim.github.io/posts/2018/2018-12-24-aggregation-tags-with-spark/">
      <h5 class="card-title">Spark</h5>
    </a>
    <p class="card-text">

<p>현재 특정 테이블의 태그정보와 아래와 같다<br />
특정컬럼에 태그 값이 컴마 구분으로 들어있음</p>

<table>
<thead>
<tr>
<th>tags</th>
</tr>
</thead>

<tbody>
<tr>
<td>태그, 태그, 태그 &hellip;</td>
</tr>
</tbody>
</table>

<h2 id="파일-처리">파일 처리</h2>

<p>해당 컬럼만 csv로 만들어본것</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#007f7f"># -*- coding: utf-8 -*-</span>

<span style="color:#fff;font-weight:bold">from</span> pyspark <span style="color:#fff;font-weight:bold">import</span> SparkConf
<span style="color:#fff;font-weight:bold">from</span> pyspark <span style="color:#fff;font-weight:bold">import</span> SparkContext
<span style="color:#fff;font-weight:bold">from</span> pyspark.sql <span style="color:#fff;font-weight:bold">import</span> SparkSession
<span style="color:#fff;font-weight:bold">from</span> pyspark.sql.types <span style="color:#fff;font-weight:bold">import</span> *


lines = sc.textFile(<span style="color:#0ff;font-weight:bold">&#39;[csv파일]&#39;</span>, use_unicode=True)
counts = lines.flatMap(<span style="color:#fff;font-weight:bold">lambda</span> line: line.split(<span style="color:#0ff;font-weight:bold">&#39;,&#39;</span>)).<span style="color:#fff;font-weight:bold">map</span>(<span style="color:#fff;font-weight:bold">lambda</span> word: (word,<span style="color:#ff0;font-weight:bold">1</span>)).reduceByKey(<span style="color:#fff;font-weight:bold">lambda</span> a,b : a + b)


schema = StructType([
  StructField(<span style="color:#0ff;font-weight:bold">&#39;tag&#39;</span>, StringType(), False),
  StructField(<span style="color:#0ff;font-weight:bold">&#39;count&#39;</span>, IntegerType(), False),
])

df = spark.createDataFrame(counts, schema)

df.show()</code></pre></div>
<p><img src="/img/spark/show-df.png" alt="show-df.png" /></p>

<h2 id="jdbc를-통해-소스-읽어오기">JDBC를 통해 소스 읽어오기</h2>

<p>그냥 jdbc를 통해서 바로 데이터프레임으로 만들어 본것</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">dbDataFrame = spark.read.format(<span style="color:#0ff;font-weight:bold">&#39;jdbc&#39;</span>) \
                             .option(<span style="color:#0ff;font-weight:bold">&#39;url&#39;</span>, url) \
                             .option(<span style="color:#0ff;font-weight:bold">&#39;dbtable&#39;</span>, <span style="color:#0ff;font-weight:bold">&#39;popular_product_ranks&#39;</span>) \
                             .option(<span style="color:#0ff;font-weight:bold">&#39;driver&#39;</span>,  driver) \
                             .option(<span style="color:#0ff;font-weight:bold">&#39;user&#39;</span>, user)
                             .option(<span style="color:#0ff;font-weight:bold">&#39;password&#39;</span>, password).load()</code></pre></div>
<h2 id="jdbc로-통해-write-처리">JDBC로 통해 Write 처리</h2>

<p>처리결과를 바로 대시보드 역할을 하는 테이블에 다시 쓰기</p>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#fff;font-weight:bold">from</span> pyspark <span style="color:#fff;font-weight:bold">import</span> SparkConf
<span style="color:#fff;font-weight:bold">from</span> pyspark <span style="color:#fff;font-weight:bold">import</span> SparkContext
<span style="color:#fff;font-weight:bold">from</span> pyspark.sql <span style="color:#fff;font-weight:bold">import</span> SparkSession
<span style="color:#fff;font-weight:bold">from</span> pyspark.sql.types <span style="color:#fff;font-weight:bold">import</span> *

<span style="color:#fff;font-weight:bold">def</span> main():
conf = SparkConf()
conf.setAppName(<span style="color:#0ff;font-weight:bold">&#39;save_tags_jdbc&#39;</span>)
sc = SparkContext(conf=conf)
spark = SparkSession(sc)

schema = StructType([
StructField(<span style="color:#0ff;font-weight:bold">&#39;tag&#39;</span>, StringType(), False),
StructField(<span style="color:#0ff;font-weight:bold">&#39;count&#39;</span>, IntegerType(), False),
])

lines = sc.textFile(<span style="color:#0ff;font-weight:bold">&#39;/home/bonjour/spark-master/data/tags.txt&#39;</span>, use_unicode=True)
counts = lines.flatMap(<span style="color:#fff;font-weight:bold">lambda</span> line: line.split(<span style="color:#0ff;font-weight:bold">&#39;,&#39;</span>)).<span style="color:#fff;font-weight:bold">map</span>(<span style="color:#fff;font-weight:bold">lambda</span> word: (word,<span style="color:#ff0;font-weight:bold">1</span>)).reduceByKey(<span style="color:#fff;font-weight:bold">lambda</span> a,b : a + b)

df = spark.createDataFrame(counts, schema)
df.write.format(<span style="color:#0ff;font-weight:bold">&#39;jdbc&#39;</span>).options(
url=<span style="color:#0ff;font-weight:bold">&#39;[jdbc url]&#39;</span>,
        user=<span style="color:#0ff;font-weight:bold">&#39;[user]&#39;</span>,
        password=<span style="color:#0ff;font-weight:bold">&#39;[password]&#39;</span>,
        driver=<span style="color:#0ff;font-weight:bold">&#39;org.mariadb.jdbc.Driver&#39;</span>,
        dbtable=<span style="color:#0ff;font-weight:bold">&#39;top_tags&#39;</span>).mode(<span style="color:#0ff;font-weight:bold">&#39;overwrite&#39;</span>).save()</code></pre></div>
<h2 id="flatmap-사용해봄">flatMap 사용해봄</h2>

<p><em>테이블 A</em></p>

<table>
<thead>
<tr>
<th>product_no</th>
</tr>
</thead>

<tbody>
<tr>
<td>1</td>
</tr>

<tr>
<td>2</td>
</tr>
</tbody>
</table>

<p><em>테이블 B</em></p>

<table>
<thead>
<tr>
<th>product_no</th>
<th>tags</th>
</tr>
</thead>

<tbody>
<tr>
<td>1</td>
<td>예쁜, 20대여성&hellip;</td>
</tr>

<tr>
<td>2</td>
<td>20대여성, 스타일이 좋은, 핏이 좋은&hellip;</td>
</tr>
</tbody>
</table>

<p>이럴 경우 flatMap을 이용해 아래와 같이 만든다</p>

<table>
<thead>
<tr>
<th>product_no</th>
<th>tag</th>
</tr>
</thead>

<tbody>
<tr>
<td>1</td>
<td>예쁜</td>
</tr>

<tr>
<td>1</td>
<td>20대여성</td>
</tr>

<tr>
<td>2</td>
<td>20대여성</td>
</tr>

<tr>
<td>2</td>
<td>스타일이 좋은</td>
</tr>
</tbody>
</table>
<div class="highlight"><pre style="color:#e5e5e5;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">df = spark.read.format(<span style="color:#0ff;font-weight:bold">&#39;jdbc&#39;</span>)\
            .option(<span style="color:#0ff;font-weight:bold">&#39;url&#39;</span>, url) \
            .option(<span style="color:#0ff;font-weight:bold">&#39;dbtable&#39;</span>, table) \
            .option(<span style="color:#0ff;font-weight:bold">&#39;driver&#39;</span>,  driver) \
            .option(<span style="color:#0ff;font-weight:bold">&#39;user&#39;</span>, user) \
            .option(<span style="color:#0ff;font-weight:bold">&#39;password&#39;</span>, password).load()

df.<span style="color:#fff;font-weight:bold">filter</span>(df[<span style="color:#0ff;font-weight:bold">&#39;tags&#39;</span>] != <span style="color:#0ff;font-weight:bold">&#39;&#39;</span>)\
  .select(df[<span style="color:#0ff;font-weight:bold">&#39;product_no&#39;</span>], df[<span style="color:#0ff;font-weight:bold">&#39;tags&#39;</span>])\
  .rdd \
  .flatMap(<span style="color:#fff;font-weight:bold">lambda</span> row: ((<span style="color:#fff;font-weight:bold">int</span>(row[<span style="color:#ff0;font-weight:bold">0</span>]), v) <span style="color:#fff;font-weight:bold">for</span> v in row[<span style="color:#ff0;font-weight:bold">1</span>].split(<span style="color:#0ff;font-weight:bold">&#39;,&#39;</span>)))</code></pre></div></p>
    <p class="card-text text-right">
      
      <a href="http://clonekim.github.io/tags/spark" class="btn btn-outline-success btn-sm">
        spark
      </a>
      
    </p>
  </div>
</div>



<div id="disqus_thread"></div>
<script type="text/javascript">
 (function() {
   
   
   if (window.location.hostname == "localhost")
     return;
   var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
   var disqus_shortname = 'clonekim-github-io';
   dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
   (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
 })();
</script>
<noscript>
  Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>




        </div></body>
</html>
